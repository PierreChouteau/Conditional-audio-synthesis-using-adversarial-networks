# Conditional audio synthesis using adversarial networks

In this project, we adapt the GANSynth model to work with a drums dataset. 
We also propose a variant to condition the training in order to obtain a model capable of generating audio based
on the desired genre.


## Install

To run our scripts, you will need to have a specific environment which will require the installation of miniconda (or anaconda). 
If you do not already have it, you can install it from the original [website](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html).


- Clone the github repository

``` 
git clone https://github.com/PierreChouteau/Conditional-audio-synthesis-using-adversarial-networks
``` 

- Create a virtual env with python 3.10.8:

``` 
conda create -n gansynth python=3.10.8
``` 

- Activate the environment:
``` 
conda activate gansynth
``` 

- Go into the repository and install the dependencies: 
``` 
cd Conditional-audio-synthesis-using-adversarial-networks
pip install -r requirements.txt
``` 

## Training

To start a default training (with the default configuration), simply run the script train.py: 

``` 
python train.py
``` 

If you want to modify the configuration (model_name, optimizers, etc...), you will have to change the config file (```default_config.yaml``` ), with the parameters you want. 


## Model Generation

You can find some of our sounds generated by our GANSynth [here](./generared_audio/).


## Project Structure

```bash 
Conditional-audio-synthesis-using-adversarial-networks
├── configs
│   └── __init__.py
│   └── config.py # global settings for our model
├── data   
├── datasets   
│   └── __init__.py
│   └── dataset.py # script to load datasets defined as Class object
│   └── helper.py # helper script for plot
├── generated_audio # folder containing some of our audio results
├── models  # folder containing models architecture defined as Class object
│   └── __init__.py
│   └── discriminator.py # discriminator architecture
│   └── gansynth.py # script containing the training of the model
│   └── generator.py # generator architecture
├── notebooks 
├── runs # directory to store the data from tensorboard
├── trained_model # directory to store the models checkpoints
├── .gitignore
├── default_config.yaml # default_configuration for training our gansynth model
├── README.md
├── requirements.txt # python dependencies necessary for the project
└── train.py # script to run the training